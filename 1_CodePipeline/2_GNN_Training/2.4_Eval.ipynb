{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99dfe9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.create_split_masks import create_split_masks, create_split_masks_regression\n",
    "import torch \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e795ec",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7693a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GNN_model import ImprovedGNN, ResidualGCN, GraphAttentionNet, ResidualGraphSAGE\n",
    "from utils.evaluate_gnn_model import evaluate_gnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3793f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_judged(model_type, data, check):\n",
    "    data_classification = torch.load(f\"data/{data}.pt\", weights_only=False)\n",
    "    model = model_type(list(data_classification.x[0].shape)[0], 64, len(data_classification.y.unique()))\n",
    "\n",
    "    train_mask_classification, val_mask_rclassification, test_mask_classification = create_split_masks(data_classification)\n",
    "    data_classification.test_mask = test_mask_classification\n",
    "\n",
    "    model_classification = model\n",
    "    model_classification.load_state_dict(torch.load(f'check/{check}.pt', map_location='cpu'))  # or 'cuda'\n",
    "    model_classification.eval()  \n",
    "    result_GNN = evaluate_gnn_model(data_classification, model_classification, mask_type='test')\n",
    "\n",
    "    return result_GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb56aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684977184977185\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8998    0.7673    0.8282     40076\n",
      "           1     0.5221    0.4832    0.5019     16618\n",
      "           2     0.0339    0.8811    0.0653       286\n",
      "\n",
      "    accuracy                         0.6850     56980\n",
      "   macro avg     0.4853    0.7105    0.4652     56980\n",
      "weighted avg     0.7853    0.6850    0.7292     56980\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30749  7317  2010]\n",
      " [ 3423  8029  5166]\n",
      " [    3    31   252]]\n"
     ]
    }
   ],
   "source": [
    "_ = model_data_judged(ImprovedGNN, \"data_quantile_Target_QC_aggcat\", \"enhanced_improved_gnn_data_quantile_Target_QC_aggcat\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
