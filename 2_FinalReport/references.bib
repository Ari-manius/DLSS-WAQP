@article{aaronhalfakerORESLoweringBarriers2020,
  title = {{{ORES}}: {{Lowering Barriers}} with {{Participatory Machine Learning}} in {{Wikipedia}}},
  author = {{Aaron Halfaker} and Halfaker, Aaron and {R. Stuart Geiger} and Geiger, R. Stuart},
  year = {2020},
  volume = {4},
  pages = {1--37},
  doi = {10.1145/3415219},
  abstract = {Algorithmic systems---from rule-based bots to machine learning classifiers---have a long history of supporting the essential work of content moderation and other curation work in peer production projects. From counter-vandalism to task routing, basic machine prediction has allowed open knowledge projects like Wikipedia to scale to the largest encyclopedia in the world, while maintaining quality and consistency. However, conversations about how quality control should work and what role algorithms should play have generally been led by the expert engineers who have the skills and resources to develop and modify these complex algorithmic systems. In this paper, we describe ORES: an algorithmic scoring service that supports real-time scoring of wiki edits using multiple independent classifiers trained on different datasets. ORES decouples several activities that have typically all been performed by engineers: choosing or curating training data, building models to serve predictions, auditing predictions, and developing interfaces or automated agents that act on those predictions. This meta-algorithmic system was designed to open up socio-technical conversations about algorithms in Wikipedia to a broader set of participants. In this paper, we discuss the theoretical mechanisms of social change ORES enables and detail case studies in participatory machine learning around ORES from the 5 years since its deployment.},
  annotation = {MAG ID: 3094328607}
}

@article{cristianconsonniWikiLinkGraphsCompleteLongitudinal2019,
  title = {{{WikiLinkGraphs}}: {{A}} Complete, Longitudinal and Multi-Language Dataset of the {{Wikipedia}} Link Networks},
  author = {{Cristian Consonni} and {David Laniado} and {A. Montresor}},
  year = {2019},
  journal = {International Conference on Web and Social Media},
  doi = {10.1609/icwsm.v13i01.3257},
  abstract = {Wikipedia articles contain multiple links connecting a subject to other pages of the encyclopedia. In Wikipedia parlance, these links are called internal links or wikilinks. We present a complete dataset of the network of internal Wikipedia links for the 9 largest language editions. The dataset contains yearly snapshots of the network and spans 17 years, from the creation of Wikipedia in 2001 to March 1st, 2018. While previous work has mostly focused on the complete hyperlink graph which includes also links automatically generated by templates, we parsed each revision of each article to track links appearing in the main text. In this way we obtained a cleaner network, discarding more than half of the links and representing all and only the links intentionally added by editors. We describe in detail how the Wikipedia dumps have been processed and the challenges we have encountered, including the need to handle special pages such as redirects, i.e., alternative article titles. We present descriptive statistics of several snapshots of this network. Finally, we propose several research opportunities that can be explored using this new dataset.},
  annotation = {ARXIV\_ID: 1902.04298\\
MAG ID: 2954330497\\
S2ID: 1bbeb28b10b99f9280a29e16f6ba04110cbd5a67},
  file = {/Users/ramius/Zotero/storage/MTUTJC96/Cristian Consonni et al. - 2019 - WikiLinkGraphs A complete, longitudinal and multi-language dataset of the Wikipedia link networks.pdf}
}

@article{edisonmarrese-taylorEditcentricApproachWikipedia2019,
  title = {An {{Edit-centric Approach}} for {{Wikipedia Article Quality Assessment}}.},
  author = {{Edison Marrese-Taylor} and {Marrese-Taylor}, Edison and {P. Loyola} and Loyola, Pablo and Matsuo, Yutaka and {Yutaka Matsuo} and Matsuo, Yutaka},
  year = {2019},
  month = nov,
  journal = {Conference on Empirical Methods in Natural Language Processing},
  pages = {381--386},
  doi = {10.18653/v1/d19-5550},
  abstract = {We propose an edit-centric approach to assess Wikipedia article quality as a complementary alternative to current full document-based techniques. Our model consists of a main classifier equipped with an auxiliary generative module which, for a given edit, jointly provides an estimation of its quality and generates a description in natural language. We performed an empirical study to assess the feasibility of the proposed model and its cost-effectiveness in terms of data and quality requirements.},
  annotation = {ARXIV\_ID: 1909.08880\\
MAG ID: 2985332770\\
S2ID: 1ec28bdcacf6fd2c72c227ccd74a2ad1ee8d4b1b},
  file = {/Users/ramius/Zotero/storage/B3ULS8YH/Edison Marrese-Taylor et al. - 2019 - An Edit-centric Approach for Wikipedia Article Quality Assessment..pdf}
}

@misc{hanGraphNeuralNetworks2020,
  title = {Graph {{Neural Networks}} with {{Continual Learning}} for {{Fake News Detection}} from {{Social Media}}},
  author = {Han, Yi and Karunasekera, Shanika and Leckie, Christopher},
  year = {2020},
  month = aug,
  number = {arXiv:2007.03316},
  eprint = {2007.03316},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2007.03316},
  urldate = {2025-08-02},
  abstract = {Although significant effort has been applied to fact-checking, the prevalence of fake news over social media, which has profound impact on justice, public trust and our society as a whole, remains a serious problem. In this work, we focus on propagation-based fake news detection, as recent studies have demonstrated that fake news and real news spread differently online. Specifically, considering the capability of graph neural networks (GNNs) in dealing with non-Euclidean data, we use GNNs to differentiate between the propagation patterns of fake and real news on social media. In particular, we concentrate on two questions: (1) Without relying on any text information, e.g., tweet content, replies and user descriptions, how accurately can GNNs identify fake news? Machine learning models are known to be vulnerable to adversarial attacks, and avoiding the dependence on text-based features can make the model less susceptible to the manipulation of advanced fake news fabricators. (2) How to deal with new, unseen data? In other words, how does a GNN trained on a given dataset perform on a new and potentially vastly different dataset? If it achieves unsatisfactory performance, how do we solve the problem without re-training the model on the entire data from scratch, which would become prohibitively expensive in practice as the data volumes grow? We study the above questions on two datasets with thousands of labelled news items, and our results show that: (1) GNNs can achieve comparable or superior performance without any text information to state-of-the-art methods. (2) GNNs trained on a given dataset may perform poorly on new, unseen data, and direct incremental training cannot solve the problem---this issue has not been addressed in the previous work that applies GNNs for fake news detection. In order to solve the problem, we propose a method that achieves balanced performance on both existing and new datasets, by using techniques from continual learning to train GNNs incrementally.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/Users/ramius/Zotero/storage/Q9TUP5YC/Han et al. - 2020 - Graph Neural Networks with Continual Learning for Fake News Detection from Social Media.pdf}
}

@misc{montiFakeNewsDetection2019,
  title = {Fake {{News Detection}} on {{Social Media}} Using {{Geometric Deep Learning}}},
  author = {Monti, Federico and Frasca, Fabrizio and Eynard, Davide and Mannion, Damon and Bronstein, Michael M.},
  year = {2019},
  month = feb,
  number = {arXiv:1902.06673},
  eprint = {1902.06673},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.06673},
  urldate = {2025-08-02},
  abstract = {Social media are nowadays one of the main news sources for millions of people around the globe due to their low cost, easy access, and rapid dissemination. This however comes at the cost of dubious trustworthiness and significant risk of exposure to `fake news', intentionally written to mislead the readers. Automatically detecting fake news poses challenges that defy existing content-based analysis approaches. One of the main reasons is that often the interpretation of the news requires the knowledge of political or social context or `common sense', which current natural language processing algorithms are still missing. Recent studies have empirically shown that fake and real news spread differently on social media, forming propagation patterns that could be harnessed for the automatic fake news detection. Propagation-based approaches have multiple advantages compared to their content-based counterparts, among which is language independence and better resilience to adversarial attacks. In this paper, we show a novel automatic fake news detection model based on geometric deep learning. The underlying core algorithms are a generalization of classical convolutional neural networks to graphs, allowing the fusion of heterogeneous data such as content, user profile and activity, social graph, and news propagation. Our model was trained and tested on news stories, verified by professional fact-checking organizations, that were spread on Twitter. Our experiments indicate that social network structure and propagation are important features allowing highly accurate (92.7\% ROC AUC) fake news detection. Second, we observe that fake news can be reliably detected at an early stage, after just a few hours of propagation. Third, we test the aging of our model on training and testing data separated in time. Our results point to the promise of propagation-based approaches for fake news detection as an alternative or complementary strategy to content-based approaches.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/ramius/Zotero/storage/5GR6C37M/Monti et al. - 2019 - Fake News Detection on Social Media using Geometric Deep Learning.pdf}
}

@article{tahayasseriDynamicsConflictsWikipedia2012,
  title = {Dynamics of Conflicts in {{Wikipedia}}.},
  author = {{Taha Yasseri} and Yasseri, Taha and {R{\'o}bert Sumi} and Sumi, R{\'o}bert and {Andr{\'a}s Rung} and Rung, Andr{\'a}s and {Andr{\'a}s Kornai} and Kornai, Andr{\'a}s and {J{\'a}nos Kert{\'e}sz} and Kert{\'e}sz, J{\'a}nos},
  year = {2012},
  month = jun,
  journal = {PLOS ONE},
  volume = {7},
  number = {6},
  doi = {10.1371/journal.pone.0038869},
  abstract = {In this work we study the dynamical features of editorial wars in Wikipedia (WP). Based on our previously established algorithm, we build up samples of controversial and peaceful articles and analyze the temporal characteristics of the activity in these samples. On short time scales, we show that there is a clear correspondence between conflict and burstiness of activity patterns, and that memory effects play an important role in controversies. On long time scales, we identify three distinct developmental patterns for the overall behavior of the articles. We are able to distinguish cases eventually leading to consensus from those cases where a compromise is far from achievable. Finally, we analyze discussion networks and conclude that edit wars are mainly fought by few editors only.},
  pmcid = {3380063},
  pmid = {22745683},
  annotation = {MAG ID: 2043253351},
  file = {/Users/ramius/Zotero/storage/4UAGSFT5/Taha Yasseri et al. - 2012 - Dynamics of conflicts in Wikipedia..pdf}
}

@article{thorstenruprechterRelatingWikipediaArticle2020,
  title = {Relating {{Wikipedia}} Article Quality to Edit Behavior and Link Structure},
  author = {{Thorsten Ruprechter} and Ruprechter, Thorsten and {Tiago Santos} and Santos, Tiago and {Denis Heli{\'c}} and Helic, Denis},
  year = {2020},
  journal = {Applied Network Science},
  volume = {5},
  number = {1},
  pages = {1--20},
  doi = {10.1007/s41109-020-00305-y},
  abstract = {Currently, the relation between edit behavior, link structure, and article quality is not well-understood in our community, notwithstanding that this relationship may facilitate editing processes and content quality on Wikipedia. To shed light on this complex relation, we classify article edits and perform an in-depth analysis of editing sequences for 4941 articles. Additionally, we build a network of internal Wikipedia hyperlinks between articles. Using this data, we compute parsimonious metrics to quantify editing and linking behavior. Our analysis unveils that conflicted articles differ substantially from others in almost all metrics, while we also detect slight trends for high-quality articles. With our network analysis we find evidence indicating that controversial and edit war articles frequently span structural holes in the Wikipedia network. Finally, in a prediction experiment we demonstrate the usefulness of edit behavior patterns and network properties in predicting conflict and article quality. With our work, we assist online collaboration communities, especially Wikipedia, in long-term improvement of content quality by offering valuable insights about the interplay of article quality, controversies and edit wars, editing behavior, and network properties via sequence-based edit and network-based article metrics.},
  annotation = {MAG ID: 3085747564\\
S2ID: d2742c2e19966865ab0db00fa515c79678eec9dd},
  file = {/Users/ramius/Zotero/storage/Q7WQFYAT/Thorsten Ruprechter et al. - 2020 - Relating Wikipedia article quality to edit behavior and link structure.pdf}
}

@article{yonglinWisdomCrowdsEffect2020,
  title = {Wisdom of Crowds: The Effect of Participant Composition and Contribution Behavior on {{Wikipedia}} Article Quality},
  author = {{Yong Lin} and Lin, Yan and {Chenxi Wang} and Wang, Chenxi},
  year = {2020},
  month = jan,
  journal = {Journal of Knowledge Management},
  volume = {24},
  number = {2},
  pages = {324--345},
  doi = {10.1108/jkm-08-2019-0416},
  abstract = {This paper aims to explore the effect of participant composition and contribution behavior of the different types of participants on the quality of knowledge generation in online communities.,This study samples all the featured articles in Chinese Wikipedia and performs a Cox regression to reveal how participant composition and contribution behavior affect the quality of articles in different contexts.,The results show that an increase in the number of participants increases the possibility of either enhancing or reducing the article quality. In most cases, the greater the proportion of core members (people who frequently participate in editing), the higher the possibility of enhancing the article quality. Occasional participants' editorial behavior hinders quality promotion, this negative effect weakens when such editorial behavior becomes more frequent.,The findings help to better leverage the role of online communities in practice and to achieve knowledge collaboration in a more efficient manner. For example, an appropriate centralized organizational form should be established in online communities to improve the efficiency of crowd contributions. And it is worth developing mechanism to encourage participants to frequently participate in editing the article.,This study contributes to the research on the organizational forms of online communities by showing the effect of participant composition and behavior in the new form of organizing on knowledge generation. This study also contributes to the research on wisdom of crowds by revealing who in a group of participants, in what context, and by what means influence knowledge generation.},
  annotation = {MAG ID: 3004113109\\
S2ID: da5790edd4224160d1da8107ba083736c9b8683e}
}


@inproceedings{redi2019citation,
  title     = {Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia’s Verifiability},
  author    = {Redi, Miriam and Fetahu, Besnik and Morgan, Jonathan and Taraborelli, Dario},
  booktitle = {Proceedings of the World Wide Web Conference (WWW)},
  year      = {2019},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/3308558.3313618},
  abstract  = {We present a taxonomy of Wikipedia's verifiability challenges and an algorithmic assessment of citation needs across articles.},
  langid    = {english}
}

@article{mernyei2020wikics,
  title     = {Wiki-CS: A Wikipedia-Based Benchmark for Graph Neural Networks},
  author    = {Mernyei, Peter and Cangea, C{\u{a}}t{\u{a}}lina},
  journal   = {arXiv preprint arXiv:2007.02901},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.02901},
  abstract  = {We introduce Wiki-CS, a novel dataset based on Wikipedia articles for evaluating graph neural networks.},
  langid    = {english}
}

@article{bassani2019quality,
  title     = {Quality of Wikipedia Articles: Analyzing Features and Building a Ground Truth for Supervised Classification},
  author    = {Bassani, Elias and Viviani, Marco},
  journal   = {Information Processing \& Management},
  volume    = {56},
  number    = {3},
  pages     = {975--988},
  year      = {2019},
  publisher = {Elsevier},
  doi       = {10.1016/j.ipm.2019.01.003},
  abstract  = {This study analyzes structural and linguistic features of Wikipedia articles to build a ground truth dataset for supervised quality classification.},
  langid    = {english}
}

@inproceedings{reddy2021nwqm,
  title     = {NwQM: A Neural Quality Assessment Framework for Wikipedia},
  author    = {Reddy, Bhanu Prakash and Bhushan, Sasi and Sarkar, Soumya and Mukherjee, Animesh},
  booktitle = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining (WSDM)},
  year      = {2021},
  pages     = {364--372},
  publisher = {Association for Computing Machinery},
  doi       = {10.1145/3437963.3441754},
  abstract  = {We propose NwQM, a neural framework for automatic quality assessment of Wikipedia articles, combining text features with neural representations.},
  langid    = {english}
}

@article{hortaribeiro2020sudden,
  title   = {Sudden Attention Shifts on Wikipedia Following COVID-19 Mobility Restrictions},
  author  = {Horta Ribeiro, Manoel and Gligoric, Kristina and Peyrard, Maxime and Lemmerich, Florian and Strohmaier, Markus and West, Robert},
  journal = {arXiv preprint arXiv:2005.08505},
  year    = {2020},
  url     = {https://arxiv.org/abs/2005.08505}
}

@inproceedings{warnckewang2015success,
  title     = {The Success and Failure of Quality Improvement Projects in Peer Production Communities},
  author    = {Warncke-Wang, Morten and Ayukaev, Vladislav R. and Hecht, Brent and Terveen, Loren G.},
  booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing (CSCW)},
  pages     = {743--756},
  year      = {2015},
  publisher = {ACM},
  doi       = {10.1145/2675133.2675241}
}

@inproceedings{le2014distributed,
  title     = {Distributed Representations of Sentences and Documents},
  author    = {Le, Quoc and Mikolov, Tomas},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML)},
  pages     = {1188--1196},
  year      = {2014}
}

@inproceedings{shen2017hybrid,
  title     = {A Hybrid Model for Quality Assessment of Wikipedia Articles},
  author    = {Shen, Aili and Qi, Jianzhong and Baldwin, Timothy},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop (ALTA)},
  pages     = {43--52},
  year      = {2017}
}

@inproceedings{shen2019multimodal,
  title     = {A Joint Model for Multimodal Document Quality Assessment},
  author    = {Shen, Aili and Salehi, Bahar and Qi, Jianzhong and Baldwin, Timothy},
  booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries (JCDL)},
  pages     = {107--110},
  year      = {2019},
  publisher = {IEEE}
}

@inproceedings{redi2019citation,
  title     = {Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia’s Verifiability},
  author    = {Redi, Miriam and Fetahu, Besnik and Morgan, Jonathan and Taraborelli, Dario},
  booktitle = {Proceedings of the World Wide Web Conference (WWW)},
  pages     = {1567--1578},
  year      = {2019},
  publisher = {ACM},
  doi       = {10.1145/3308558.3313618}
}

@article{kipf2016semi,
  title   = {Semi-Supervised Classification with Graph Convolutional Networks},
  author  = {Kipf, Thomas N. and Welling, Max},
  journal = {arXiv preprint arXiv:1609.02907},
  year    = {2016},
  url     = {https://arxiv.org/abs/1609.02907}
}

@article{velickovic2017gat,
  title   = {Graph Attention Networks},
  author  = {Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
  journal = {arXiv preprint arXiv:1710.10903},
  year    = {2017},
  url     = {https://arxiv.org/abs/1710.10903}
}

@article{wu2019gnn,
  title   = {A Comprehensive Survey on Graph Neural Networks},
  author  = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  journal = {arXiv preprint arXiv:1901.00596},
  year    = {2019},
  url     = {https://arxiv.org/abs/1901.00596}
}

@article{yang2016revisiting,
  title   = {Revisiting Semi-Supervised Learning with Graph Embeddings},
  author  = {Yang, Zhilin and Cohen, William W. and Salakhutdinov, Ruslan},
  journal = {arXiv preprint arXiv:1603.08861},
  year    = {2016},
  url     = {https://arxiv.org/abs/1603.08861}
}

@article{shchur2018pitfalls,
  title   = {Pitfalls of Graph Neural Network Evaluation},
  author  = {Shchur, Oleksandr and Mumme, Maximilian and Bojchevski, Aleksandar and G{\"u}nnemann, Stephan},
  journal = {arXiv preprint arXiv:1811.05868},
  year    = {2018},
  url     = {https://arxiv.org/abs/1811.05868}
}

@article{klicpera2018personalized,
  title   = {Personalized Embedding Propagation: Combining Neural Networks on Graphs with Personalized PageRank},
  author  = {Klicpera, Johannes and Bojchevski, Aleksandar and G{\"u}nnemann, Stephan},
  journal = {arXiv preprint arXiv:1810.05997},
  year    = {2018},
  url     = {https://arxiv.org/abs/1810.05997}
}


@inproceedings{kumar2016disinformation,
  title={Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes},
  author={Kumar, Srijan and West, Robert and Leskovec, Jure},
  booktitle={Proceedings of the 25th International Conference on World Wide Web},
  year={2016},
  pages={591--602},
  publisher={International World Wide Web Conferences Steering Committee},
  doi={10.1145/2872427.2883085}
}

@article{ruprechter2020relating,
  title={Relating Wikipedia article quality to edit behavior and link structure},
  author={Ruprechter, Thorsten and Santos, Tiago and Helic, Denis},
  journal={Applied Network Science},
  volume={5},
  number={1},
  pages={61},
  year={2020},
  publisher={Springer}
}
@article{arroyo2020science,
  title={Science through Wikipedia: A novel representation of open knowledge through co-citation networks},
  author={Arroyo-Machado, Wenceslao and Torres-Salinas, Daniel and Herrera-Viedma, Enrique and Romero-Fr{\'\i}as, Esteban},
  journal={PloS one},
  volume={15},
  number={2},
  pages={e0228713},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}