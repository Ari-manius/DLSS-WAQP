---
title: "Wikipedia Article Quality Prediction"
subtitle: "Final Report: DLSS"
author: 
  - name: "Nafiseh Tavakol, Kuon Ito, Lorenz, Rückert, Marius Helten"
    affiliation: "1406810"
editor: visual
date: "`r format(Sys.Date(), '%B %d, %Y')`" 
format:
  pdf:
    colorlinks: true
    links-as-notes: true
    include-in-header: |
      % Margins
      \geometry{top=0.7in, bottom=0.7in, left=0.6in, right=0.6in}

      % Slightly tighter line spacing (helps overall)
      \usepackage{setspace}
      \setstretch{1.02}

      % Force compact paragraphs after all packages load
      \AtBeginDocument{%
        \setlength{\parskip}{0pt}%  no vertical gap between paragraphs
        \setlength{\parindent}{1em}% small indent to mark new paragraph
      }

      % Most visible spacing is around headings – tighten it
      \usepackage{titlesec}
      \titlespacing*{\section}{0pt}{0.6\baselineskip}{0.25\baselineskip}
      \titlespacing*{\subsection}{0pt}{0.45\baselineskip}{0.2\baselineskip}
      \titlespacing*{\subsubsection}{0pt}{0.4\baselineskip}{0.18\baselineskip}

      % Lists also add space – remove it
      \usepackage{enumitem}
      \setlist{nosep}
    

header-includes:
  - \usepackage{titling}  
  - \pretitle{\begin{center}\LARGE\bfseries} 
  - \posttitle{\end{center}}  
  - \preauthor{\begin{center} \large} 
  - \postauthor{\end{center}} 
  - \predate{\begin{center}\large} 
  - \postdate{\begin{figure}[H]
      \centering
      \includegraphics[width=1.0\textwidth]{Images/placeholder.png}
    \end{figure}
    \end{center}} 
bibliography: references.bib
cite-method: citeproc
link-citations: true
execute:
  echo: false
  warning: false
  message: false
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(error = TRUE)
```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
data_descriptive <- read.csv("/Users/ramius/Desktop/CodeVault/01_Project/Uni/DLSS_DeepLearningforSocialScientists/Final_Project/DLSS-WAQP/2_FinalReport/Tables/Wiki_metrics.csv")

data_homophily <- read.csv("/Users/ramius/Desktop/CodeVault/01_Project/Uni/DLSS_DeepLearningforSocialScientists/Final_Project/DLSS-WAQP/2_FinalReport/Tables/Wiki_assortativity.csv")
```

# **Introduction**

The Web enables anyone to read, publish, and share information at unprecedented speed and scale, greatly benefiting billions but also creating fertile ground for falsehoods [@kumar2016disinformation]. Wikipedia, as one of the most widely used sources of free knowledge, faces credibility concerns due to hoaxes and the risk of low-quality or biased contributions [@hortaribeiro2020sudden; @kumar2016disinformation; @bassani2019quality]. Although the platform employs a grading scheme from Featured Articles (FA) to Stubs, only a very small fraction of articles reach the highest quality levels, creating an imbalance that resembles anomaly detection, where rare but important cases must be identified [@warnckewang2015success; @bassani2019quality]. To address this, both manual and automated quality assessment methods have been explored. Human volunteers and WikiProjects monitor content, but scale and subjectivity limit their effectiveness. Automated approaches progressed from handcrafted textual features to machine learning models such as doc2vec [@le2014distributed], BiLSTMs, and multimodal systems that integrate images and metadata. Reddy et al. [@reddy2021nwqm] showed that multimodal learning substantially improves prediction, while Bassani and Viviani [@bassani2019quality] highlighted the challenges of reliable ground truth and found textual features more predictive than network ones. Verifiability is another key dimension: Redi et al. [@redi2019citation] introduced a taxonomy of citation reasons and showed that citation practices strongly signal credibility. Yet, as of 2019, more than 350,000 articles carried a tag, suggesting widespread unverified claims. Recent advances in Graph Neural Networks (GNNs) open new opportunities to model Wikipedia not only through text but also through its citation structures. Traditional citation benchmarks (Cora, CiteSeer, PubMed) suffer from limited diversity [@yang2016revisiting; @shchur2018pitfalls], leading to the introduction of Wiki-CS, a richer Wikipedia-based dataset [@mernyei2020wikics]. Within this landscape, approaches can be divided into content-based, focusing on semantics and syntax, and context-based, emphasizing external signals such as social or citation networks [@montiFakeNewsDetection2019].

Our project adopts a context-based perspective, leveraging both article relations (external references) and article structure (sections, citations, length). By applying GNNs, we aim to model how signals of reliability and authority propagate through these networks, while complementing them with additional structural features. This network-oriented approach avoids reliance on semantics or style, offering a generalizable and scalable framework for predicting Wikipedia article quality.

# Data

## Data Collection

This project combined four complementary data sources to capture different aspects of Wikipedia articles: the Wikipedia Dump (raw text and structure), the Pageviews API (popularity and user attention), the Edit History API (editorial activity patterns, including user and bot edits), and the Wikipedia API (article crawling and network construction). Article metadata was retrieved by mapping page IDs to titles via the MediaWiki API, which only supports up to 50 IDs per request; page IDs were split into batches of 50, queried in parallel with ThreadPoolExecutor, and merged back into the dataset before saving to CSV. One year of pageview data (July 2023–July 2024) was collected for each article from the Wikimedia REST API, aggregated into annual totals, and stored incrementally to prevent data loss; parallel requests and tqdm progress tracking ensured efficiency. Temporal metadata was added by retrieving last edit timestamps through the REST API’s `/page/summary/{title}` endpoint, using randomized delays (0.3–0.6s), retry logic for HTTP 429 errors, and parallel workers to accelerate processing; results were saved to `final_last_edit.csv`. Editorial activity was captured for July 2023–July 2025, with edit counts broken down by registered users, anonymous users, group bots, and name bots, then aggregated into human vs. bot contributions. To respect API limits, randomized delays, proxy rotation, and periodic checkpoints were used, and data collection was parallelized for efficiency. Together, these steps produced a comprehensive dataset covering article text and structure, popularity, recency, editorial activity, and network relationships, providing a robust foundation for downstream analyses.

The network was obtained by a BFS-search starting at a handful of seed articles (**exact number at least**) and then expanding this seed through following internal links until a sufficient network size was reach. This gave a snowball sample of the whole of wikipedia. It has to be noted that this provides a biased sample of the network, that by no means is representative of all of wikipedia.

## Dataset Analysis

### Article Features

A dataset of 379,926 English Wikipedia articles was assembled to support the quality prediction task. The collection combines article-level features, structural metadata, and editing history, enabling both content-independent and behavioral dimensions of quality to be examined. Articles span the full range of Wikipedia’s grading scheme, from Stub to Featured Article (FA), ensuring coverage of different writing styles, completeness levels, and editorial efforts. The design of this dataset is informed by prior research on text, structure, and verifiability [-@bassani2019quality], [-@reddy2021nwqm], [-@redi2019citation] as well as graph-based benchmarks such as Wiki-CS [-@mernyei2020wikics]. Drawing on these insights, the dataset integrates both article-level descriptors and network-oriented variables.

For each article, descriptive attributes include page length, number of references, number of sections, templates, infobox presence, and pageviews. Structural metadata records the number of categories, links, and depth in the category hierarchy. Editorial activity is tracked through detailed revision histories, separating human and bot edits and further distinguishing between registered, anonymous, and automated accounts. To reflect recent collaboration dynamics, edit-related variables were restricted to the past two years. Finally, additional context such as last edit timestamp, days since last edit, and protection status was included to capture recency and stability. This design results in a dataset that captures both structural and editorial signals, complementing traditional content-based features and enabling a multi-perspective analysis of Wikipedia article quality.

```{r}
library(knitr)
library(dplyr)

# Define variables, categories, and definitions
vars <- tribble(
  ~Category, ~Variable, ~Definition,
  "Structure","num_categories","Number of categories assigned to the article.",
  "Structure","num_links","Total number of internal/external links.",
  "Structure","page_length","Length of the article (characters).",
  "Structure","num_references","Number of citations in the article.",
  "Structure","num_sections","Number of sections.",
  "Structure","num_templates","Number of templates used.",
  "Structure","has_infobox_encoded","1 if an infobox exists, otherwise 0.",
  "Structure","protection_status_encoded","Encoded protection level.",
  "Style / Semantic","assessment_source_umap_1","UMAP dim 1 of assessment source.",
  "Style / Semantic","assessment_source_umap_2","UMAP dim 2 of assessment source.",
  "Style / Semantic","assessment_source_umap_3","UMAP dim 3 of assessment source.",
  "Network","days_since_last_edit","Days since the last edit.",
  "Network","edits_all_types","Total edits (last two years).",
  "Network","edits_anonymous","Anonymous edits (last two years).",
  "Network","edits_bot","Bot edits (last two years).",
  "Network","edits_group_bot","Group-bot edits (last two years).",
  "Network","edits_human","Human edits (last two years).",
  "Network","edits_name_bot","Named-bot edits (last two years).",
  "Network","edits_user","Registered-user edits (last two years).",
  "Network","pageviews_Jul2023Jul2024","Pageviews from Jul 2023–Jul 2024."
)

# Render table
kable(vars, caption = "Variables grouped by category with their definitions")
```

### Target Variable: Article Quality

Wikipedia articles are rated on an ordinal quality scale. In this project the following classes are used as the target: FA, FL, FM, A, GA, B, C, Start, Stub, List.

```{r}
library(knitr)
library(dplyr)

quality_classes <- tribble(
  ~Class, ~Meaning,
  "FA", "Featured Article – highest quality, comprehensive and well-sourced",
  "FL", "Featured List – best-quality lists, complete and well-referenced",
  "FM", "Featured Media – high-quality non-textual media (images, videos, etc.)",
  "A", "Near-featured quality, but may need minor improvements",
  "GA", "Good Article – accurate, well-structured, but less comprehensive than FA",
  "B", "Mostly complete, but still lacking references or polish",
  "C", "Useful coverage, but incomplete or missing important details",
  "Start", "Basic coverage, underdeveloped but beyond stub level",
  "Stub", "Very short or incomplete article, minimal information",
  "List", "Articles in list format, assessed on completeness and structure"
)

kable(quality_classes, caption = "Wikipedia quality assessment classes and their meaning")
```

### Data Exploration

The dataset comprises \~380,000 Wikipedia articles labeled with quality classes, but the distribution is highly imbalanced: most articles fall into low-quality categories (Stub, Start), while only a small minority reach high-quality levels (FA, GA, FL, A). Quality progression is evident—higher-quality articles are much longer and include richer structural and citation features such as references, links, and sections. In contrast, Stub and Start articles remain short and sparsely referenced, reflecting limited editorial development. These patterns confirm that structural richness and citation density are closely associated with editorial quality.

```{r}
library(tibble)
library(dplyr)
library(scales)
library(knitr)

tbl <- tribble(
  ~`Quality Class`, ~Count, ~`Avg. Page Length`, ~`Avg. References`, ~`Avg. Links`, ~`Avg. Sections`,
  "A",     113,    60096.51,  97.15, 386.11, 17.62,
  "B",   29768,    61135.93,  96.63, 422.76, 21.02,
  "C",   74983,    33138.79,  47.86, 285.05, 14.69,
  "FA",   1582,    89048.49, 142.50, 514.55, 21.72,
  "FL",    320,    58989.33,  87.65, 370.57, 11.29,
  "GA",   5934,    64000.73, 115.96, 395.99, 17.88,
  "List", 13161,   29490.59,  29.69, 368.69, 13.75,
  "Start",162145,  14064.61,  17.70, 179.28,  8.25,
  "Stub", 91920,    5878.57,   6.29, 143.61,  4.21
) |>
  mutate(
    Count = comma(Count),
    `Avg. Page Length` = comma(`Avg. Page Length`, accuracy = 0.01),
    `Avg. References`  = number(`Avg. References`,  accuracy = 0.01),
    `Avg. Links`       = number(`Avg. Links`,       accuracy = 0.01),
    `Avg. Sections`    = number(`Avg. Sections`,    accuracy = 0.01)
  )

kable(tbl, caption = "Quality classes and average structural metrics.")
```

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/quality_distribution.png}
    \caption{Wikipedia Graph - Degree Distribution and Power Law Analysis}
    \label{fig:pca_combined}
\end{figure}

The heatmap shows strong correlations among structural features, with the highest between page length and references (0.86), indicating that longer articles are usually better structured and more thoroughly referenced. Links are also positively correlated but provide partly independent information. A log–log scatter plot of links versus references confirms this trend: articles with more links often include more references, though variation remains, showing that links and references capture complementary aspects of article richness.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/features_corr.png}
    \caption{Wikipedia Graph - Degree Distribution and Power Law Analysis}
    \label{fig:pca_combined}
\end{figure}

In Feature Distributions plots, most articles cluster at the low end for page length, references, links, sections, pageviews, and recency of edits, with only a few outliers reaching extreme values—reflecting Wikipedia’s heterogeneity, where a small subset dominates in depth and attention..

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/features_dis.png}
    \caption{Wikipedia Graph - Degree Distribution and Power Law Analysis}
    \label{fig:pca_combined}
\end{figure}

Pageviews vary widely across classes. While Featured Articles (FA) and Good Articles (GA) generally attract higher median views, many B-class and even lower-quality articles also reach high visibility. This suggests that popularity is not fully aligned with editorial quality, articles can be widely read even if their structural quality is limited.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/pageview.png}
    \caption{Wikipedia Graph - Degree Distribution and Power Law Analysis}
    \label{fig:pca_combined}
\end{figure}

Feature Relationships Pairwise feature comparisons show clear clustering by quality: high-quality articles combine length, references, links, and sections in consistent proportions, while low-quality articles remain compact across all dimensions. Pageviews and recency of edits add further variation but only partially align with quality, reinforcing that structural completeness and editorial effort are the strongest signals of quality.

### Network Description

As already mentioned we create the network from the sampled articles using the internal links of wikipedia articles. This way we obtained a directed network with a single weakly connected component. The network has a  The network is very sparse (Density = 0.0002), which is no suprise for a network of this size. There is also some clustering in the network and the graph has a small diameter (approximated). This make sense since the articles were obtained by BFS and collection did not go further than 2-3 steps. Notable is the high share of reciprocal relations which shows that many articles link each other. 

```{r, echo=FALSE}
knitr::kable(data_descriptive, caption = "Network Descriptive Metrics", 
              digits = 5, 
              format.args = list(scientific = FALSE))
```

The degree distributions for the network are very long tailed, which is typical for many internet and citation networks. This can the consequence of the age of articles or some sort of preferential attachment or local redirection mechanism.  
We see some difference between In- and Out-Degree. In-degrees have a much higher range, up to 75k, while Out-degrees are much smaller, up to 2,5k. This is because an article can be linked to many more articles than it can link itself. Interestingly the means are very similar. 
The power-law is a marginally better fit for the In-degrees (smaller KS-distance) and $\alpha_{In}$ is lower, but still above 2.

\begin{figure}[H]
    \begin{subfigure}{0.5\textwidth} % Adjust width as needed
        \centering
        \includegraphics[width=\textwidth]{Images/InDegree_PowerLaw.png}
        \label{fig:Number of Components}
    \end{subfigure}
    \hfill % This adds space between the two subfigures
    \begin{subfigure}{0.5\textwidth} % Adjust width as needed
        \centering
        \includegraphics[width=\textwidth]{Images/OutDegree_PowerLaw.png}
        \label{fig:Biggest (weakly) Connected Component}
    \end{subfigure}
    \caption{Degree Distributions with Power Law Fits}
    \label{fig:pca_combined}
\end{figure}

For none of the tested attributes strong assortativity was measured, with different implications. 
For the degree there is no homophily or heterophily between articles of similar or dissimilar, in- or out-degrees. Showing that the network is not forming structures along these properties.

```{r, echo=FALSE}
knitr::kable(data_homophily, caption = "Network Assortativity", 
              digits = 4, 
              format.args = list(scientific = FALSE))
```

For the Article-Quality the network is also not showing notable assortativity. There are only marginal increases by changing the encoding of the varibles, either by aggregating categorical varibles or switching to a numerical encoding. Higher values would have proved that articles form homogenous communities based on their quality. This already strongly discourages the hypothesis that Quality-signals propagate directly through channels in the network and only leaves the option of other node-properties being connected to certain qualities. It also already foreshadows why the direct network structure does not provide much help in classifying the article-nodes, since many GNNs rely on homophily by aggregating information from the neighborhood of nodes. 

### Network Features

To further enrich the dataset we use the wikipedia graph to create network based features for the article-nodes. The hope is that these will provide crucial additional information to help classifying them. For example it is conceiveable that certain article-qualities are associated with certain structural positions in the network. 

```{R}
network_features_tbl <- tribble(
  ~`Feature Category`, ~`Feature Name`,
  "Degree Centrality", "In-Degree",
  "Degree Centrality", "Out-Degree", 
  "Local Structure", "Clustering Coefficient",
  "Path-based", "Betweenness Centrality",
  "Core Structure", "Coreness Centrality",
  "Link Analysis", "PageRank",
  "Link Analysis", "HITS Hub Score",
  "Link Analysis", "HITS Authority Score",
  "Reciprocity", "Share of Reciprocal Relations",
  "Spectral Features", "Spectral Embedding (9D)",
  "Spectral Features", "Spectral Modularity Row Sums",
  "Probabilistic Features", "Transition Probability Max"
)

kable(network_features_tbl, caption = "Network-based features extracted from Wikipedia Graph")
```

In the following plots we have separated the articles by their quality. For consistency, the observed trend should preserve the quality-category order (HQ-MQ-LQ). The plotted values are pre-quantile-scaling as that would have greatly hampered their interpretability. 

For In-Degree we see the very low share of very high in-degree articles, mainly in the MQ category. On the lower end of the in-degrees ($<5000$) we see that HQ articles have a higher share of articles with increasing in-degree.
For the Out-Degree this is much more visible, showing that higher quality articles tend to link to more articles.

The clustering shows that higher quality articles tend to be less clustered, so more functioning as hubs, inhabiting bridging positions, also when having more conenctions share of relations between neighbors rises much slower. Which is also supported by the relatively higher Betweenness centrality. 
Here the Coreness Centrality somehow speaks of a different picture, showing higher quality networks are more deeply embedded into the network. 

For Page-Rank and both HITS centralities (Hubs and Authority) we see clearly, at least for the Hubs-Score, that higher Quality articles posses higher scores. Unfortunatly this becomes less clear for Authority and Pagerank scores, because of the width of the distributions, showing that a large majority of all articles posses very low scores, but the general trend (HQ>MQ>LQ) held. Here the sampling method might have produced these exceptionally high values, though this is also conformed by the other node-level measures. 

A very interesting case is the share of reciprocal relations. Here we see for HQ and MQ higher shares of low reciprocity and lower shares of high reciprocity. Interestingly LQ articles show a very steady almost linear decline. Which also fits well with the In- and Out-degree results. 

All these results point towards a qualitative difference in node-properties relating to article quality and thus should provide helpful information for classification.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/netfeatures_category.png}
    \caption{CCDF for Network Features of Wikipedia Graph}
    \label{fig:pca_combined}
\end{figure}

Furthermore we created a 9-Dimensional Spectral Embedding for the graph and used it as features for the dataset. Spectral embedding maps nodes to a low-dimensional space using eigenvectors of graph matrices (like the Laplacian), where the geometric distances preserve the graph's structural relationships. The embedding for the 2-D plot was chosen by the largest eigenvalue gap.
There is some notable separation over the space, notably along 3-lines. Here probably also the sample structure played a major role in shaping this feature. 
In the plot we can also see that certain areas are more densely populated by either green or blue, which could be taken as a sign that certain article qualities inhabit a different structural position in the network. This would also support our earlier findings for the other network-features. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/2dspectral.png}
    \caption{2D Spectral Node Embedding produce by Wikipedia Graph Sample}
    \label{fig:pca_combined}
\end{figure}

## Preprocessing

During the pre-processing we face two important challenges. The first was the highly imbalanced target variable with only a very small fraction of high-quality articles. The second challenge were the heavily skewed distributions, especially for the graph based features. These have to be adressed to get

The dataset was prepared for modeling by constructing target labels and encoding structured features. Articles were indexed by title, page ID, and numeric identifiers for efficient lookup. Each article was mapped to its Wikipedia quality class (FA, GA, B, etc.), from which three target variables were derived: a 10-level ordinal scale (`Target_QC_cat`), a 3-tier aggregate scale (`Target_QC_aggcat`) (High Quality (HQ) > Medium Quality (MQ) > Low Quality (LQ) ), and a log-transformed numeric variant (`Target_QC_numlog`). 

Categorical and binary article-attributes were encoded, including protection status (integer labels), infobox presence (binary), and assessment source (one-hot, then reduced with UMAP). The final feature set integrated content metrics (page length, sections, templates, references, categories, links), editorial activity (days since last edit, human vs. bot edits), and popularity (annual pageviews, July 2023–July 2024). Together, these features capture structural, editorial, and popularity dimensions of Wikipedia articles, providing information for the models.

The features had to be preprocessed since the numerical ranges for many features, especially the network features, were very concentrated to a small range and thus not fit for training. Here normalization proved to be insufficient. The distributions particularly for the network metrics are immensely positvely skewed. Different scaling methods such as standard, minmax, robust and robust-log scaling proved to be ineffective to generate reasonably spread distributions. The only approach that brought reasonable results was quantile scaling. Quantile scaling transforms data by mapping each value to its percentile rank, creating a uniform distribution where extreme outliers get compressed while preserving relative order.

From the wikipedia graphs we removed nodes with total $degree(k) ≤ 1$.

The Wikipedia dataset was converted from graph-tool format into PyTorch Geometric Data objects, with all node features. Each processed graph was stored in two forms: a PyTorch tensor dataset (`.pt`) for GNN training and a Parquet file for feature inspection and debugging. An extra dataset with only article-features was created to compare if using the network features provided helpful information.

# Methods

## Benchmarks

### Machine-Learning

### Multi-Layer-Perceptron

## Graph-Neural-Network Models

- Hyperparameter Search 

### Graph-Convolutional

-   Improved GNN
-   Residual GCN

### Graph-Sage

### Graph Attention

## Training and Evaluation

\begin{figure}[H]
    \begin{subfigure}{0.3\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Images/enhanced_improved_gnn_data_quantile_Target_QC_aggcat_run1.png} %Path to images 
        \label{fig:Multilayer Perceptron}
        \caption{GCN} %Visible Caption
    \end{subfigure}
    \hfill 
    \begin{subfigure}{0.3\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Images/enhanced_residual_gcn_data_quantile_Target_QC_aggcat_run1.png}
        \label{fig:Concolutional Graph Neural Network}
        \caption{Residual GCN} %Visible Caption
    \end{subfigure}
    \hfill 
    \begin{subfigure}{0.3\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Images/enhanced_residual_sage_data_quantile_Target_QC_aggcat_run1.png}
        \label{fig:GraphSAGE Model} %Invisible! 
        \caption{Residual Sage} %Visible Caption
    \end{subfigure}
    \caption{Test and Validation Loss and Accuracy during Training I} %Visible Caption 
    \label{fig:}
\end{figure}


\begin{figure}[H]
    \begin{subfigure}{0.3\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Images/enhanced_gat_data_quantile_Target_QC_aggcat_run1.png} %Path to images 
        \label{fig:Multilayer Perceptron}
        \caption{GAT} %Visible Caption
    \end{subfigure}
    \hfill 
    \begin{subfigure}{0.3\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Images/enhanced_mlp_data_quantile_Target_QC_aggcat_run1.png}
        \label{fig:Concolutional Graph Neural Network}
        \caption{MLP Network- and Article-Features} %Visible Caption
    \end{subfigure}
    \hfill 
    \begin{subfigure}{0.3\textwidth} 
        \centering
        \includegraphics[width=\textwidth]{Images/enhanced_mlp_data_nonnetwork_quantile_Target_QC_aggcat_run1.png}
        \label{fig:GraphSAGE Model} %Invisible! 
        \caption{MLP Article-Features} %Visible Caption
    \end{subfigure}
    \caption{Test and Validation Loss and Accuracy during Training II} %Visible Caption 
    \label{fig:}
\end{figure}

# Results

(Performance comparison tables, learning curves, confusion matrices)

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=8cm, keepaspectratio]{Images/CV_Results_with_ErrorBars.png}
    \caption{Evaluation Metrics for NN-Models}
    \label{fig:pca_combined}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=5cm, keepaspectratio]{Images/Averaged_Confusion_Matrices.png}
    \caption{Confusion Matrices for NN-Models}
    \label{fig:pca_combined}
\end{figure}

# Discussion and Conclusion

(Performance Comparison, Interpret the results in the context of social network theory, Key Findings and Implications)

- Sampling method biased
- more extensive testing of architectures and parameters
- missing assortativity/homophily -> no direct quality propagation (providing network structure did not meaningfully improve GNNs over MLP)
- some hints for network structure and position being related article quality (MLP performed better), which by a few percentage points is already remarkable, as these have to be stacked in order to provide meaningful improvements

# References

## Code and Data

-   API´s
-   Python Packages

## Literature

-   Citeable papers